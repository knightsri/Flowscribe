# Flowscribe â€“ Automated C4 Architecture Analysis & Documentation

## Overview
Flowscribe automates generation, visualization, and review of multi-level C4 architecture models for large repositories.
It integrates static analysis (Deptrac), dynamic LLM review (context-aware prompts), and cost tracking (usage-first accounting)
to produce end-to-end architecture insights.

## Project Structure

```
Flowscribe/
â”œâ”€â”€ .github/              # GitHub Actions workflows and templates
â”‚   â””â”€â”€ workflows/        # CI/CD pipeline definitions
â”œâ”€â”€ docs/                 # Documentation
â”‚   â”œâ”€â”€ CODING_STANDARDS.md  # Coding standards and best practices
â”‚   â”œâ”€â”€ prompts/          # LLM prompts for architecture analysis
â”‚   â””â”€â”€ TODO.md           # Development tasks and roadmap
â”œâ”€â”€ scripts/              # Main application scripts
â”‚   â”œâ”€â”€ c4-level1-generator.py      # C4 Level 1 (System Context) generator
â”‚   â”œâ”€â”€ c4-level2-generator.py      # C4 Level 2 (Container) generator
â”‚   â”œâ”€â”€ c4-level3-generator.py      # C4 Level 3 (Component) generator
â”‚   â”œâ”€â”€ c4-level4-generator.py      # C4 Level 4 (Code) generator
â”‚   â”œâ”€â”€ c4-architecture-review.py   # Architecture review generator
â”‚   â”œâ”€â”€ create-master-index.py      # Master index aggregator
â”‚   â”œâ”€â”€ flowscribe-analyze.py       # Main orchestration script
â”‚   â”œâ”€â”€ flowscribe_utils.py         # Shared utilities (LLM client, cost tracking)
â”‚   â”œâ”€â”€ logger.py                   # Logging configuration
â”‚   â”œâ”€â”€ constants.py                # Centralized constants
â”‚   â”œâ”€â”€ error_sanitizer.py          # Error message sanitization
â”‚   â”œâ”€â”€ config_validator.py         # Configuration validation
â”‚   â””â”€â”€ sanitize_output_files.py    # Output file sanitizer
â”œâ”€â”€ tests/                # Test suite
â”‚   â”œâ”€â”€ unit/             # Unit tests
â”‚   â”œâ”€â”€ integration/      # Integration tests
â”‚   â””â”€â”€ conftest.py       # Pytest configuration
â”œâ”€â”€ .env.example          # Example environment variables
â”œâ”€â”€ .gitignore            # Git ignore patterns
â”œâ”€â”€ CHANGELOG.md          # Version history and changes
â”œâ”€â”€ CODE_QUALITY_IMPROVEMENTS_SUMMARY.md  # Code quality tracking
â”œâ”€â”€ CONTRIBUTING.md       # Contribution guidelines
â”œâ”€â”€ Dockerfile            # Docker container definition
â”œâ”€â”€ docker-compose.yml    # Docker Compose configuration
â”œâ”€â”€ LICENSE               # MIT License
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ requirements-dev.txt  # Development dependencies
â”œâ”€â”€ SECURITY.md           # Security policy
â”œâ”€â”€ Setup.md              # Setup and installation guide
â””â”€â”€ Task-List.md          # Project task tracking
```

### Key Directories

- **`scripts/`**: Contains all Flowscribe Python scripts for C4 generation and analysis
- **`tests/`**: Comprehensive test suite with unit and integration tests
- **`docs/`**: Project documentation including coding standards and prompts
- **`.github/`**: CI/CD workflows and GitHub configuration

### Typical Project Locations

When analyzing projects, Flowscribe uses the following default paths:

- **Workspace directory**: `/workspace/projects/` (configurable via `--workspace`)
- **Output directory**: `/workspace/output/` (configurable via `--output`)
- **Clone location**: `{workspace}/{project-name}/`
- **Generated docs**: `{output}/{project-name}/`

Example:
```bash
# Project is cloned to:
/workspace/projects/WordPress/

# Documentation is generated in:
/workspace/output/WordPress/
â”œâ”€â”€ c4-level1.md
â”œâ”€â”€ c4-level2.md
â”œâ”€â”€ c4-level3-*.md
â”œâ”€â”€ c4-level4.md
â”œâ”€â”€ architecture-review.md
â””â”€â”€ master-index.md
```

## Core Features
- Automated C4 Level 1â€“4 document generation
- AI-driven architecture review using premium LLMs (Sonnet 4.5, Xi Fast Code)
- Cost-aware metrics and usage validation (OpenRouter accounting)
- Provenance stamping and audit logging
- Extensible Mermaid-based visualization with Deptrac layer integration

## Architecture & Workflow
Flowscribe follows a modular pipeline:

1. **Dependency Analysis (Deptrac)** â€“ Identifies cross-layer calls and structural violations.
2. **C4 Model Generation** â€“ Sequential L1 â†’ L4 markdown generation using task-specific LLM prompts.
3. **Architecture Review** â€“ Deep architectural inspection with Sonnet 4.5, outputting recommendations.
4. **Metrics Aggregation** â€“ Canonicalized metrics schema (v1.0) across all scripts for uniform cost tracking.
5. **Visualization Rendering** â€“ Rich layered overview using Mermaid with true inter-layer arrows.
6. **Validation & Provenance** â€“ Hash-stamped outputs for reproducibility and verification.

## Visualization
Flowscribeâ€™s visualization layer uses the Deptrac ruleset to render actual dependencies between layers.

### Example: Inter-Layer Dependency Diagram (via Deptrac Ruleset)

```mermaid
flowchart TB
    subgraph Presentation["Presentation Layer"]
        Controller[Controller Layer]
    end

    subgraph Domain["Domain Layer"]
        Service[Service Layer]
    end

    subgraph Infrastructure["Infrastructure Layer"]
        Database[(Database)]
        External["External Services"]
    end

    Controller --> Service
    Service --> Database
    Service --> External
```
> **Note:** Layers with no direct dependencies are displayed in gray for completeness.

## Metrics & Costing
Flowscribe adopts a **usage-first** approach where all cost metrics are sourced directly from OpenRouter API usage data.
Each script reports metrics in a canonical schema:

| Field | Description |
|-------|--------------|
| `model` | LLM model used (e.g., claude-sonnet-4.5) |
| `tokens_in` / `tokens_out` | Prompt and completion tokens |
| `cost_usd` | Cost derived from OpenRouter accounting |
| `duration_sec` | Execution time |
| `source` | Script or level producing this metric |

### Example Cost Summary (aggregated)
| Stage | Model | Cost (USD) | Tokens (in/out) | Duration (s) |
|--------|--------|-------------:|-----------------:|-------------:|
| ğŸ§­ C4 Level 1 | gpt-4o-mini | 0.0065 | 2,345 / 2,001 | 58.3 |
| ğŸ—ï¸ C4 Level 2 | gpt-4o-mini | 0.0102 | 4,231 / 3,765 | 102.1 |
| ğŸ§© C4 Level 3 | gpt-4o-mini | 0.0087 | 3,221 / 2,998 | 95.4 |
| âš™ï¸ C4 Level 4 | claude-sonnet-4.5 | 0.0198 | 8,750 / 7,690 | 165.4 |
| ğŸ§± Architecture Review | claude-sonnet-4.5 | 0.0133 | 8,750 / 7,690 | 165.4 |
| ğŸ’¼ **TOTAL** |  | **$0.0585** | **27,297 / 24,144** | **586.6** |

_Legend: â€œinâ€ = prompt tokens, â€œoutâ€ = completion tokens. Costs use OpenRouter usage accounting._

## Validation & Provenance
All generated files include provenance stamps for traceability:

- **Hashing** â€“ Each markdown is SHA256-hashed post-generation.
- **Versioning** â€“ Scripts include `flowscribe_utils` version stamps.
- **Verification tools** â€“
  - `flowscribe verify-metrics` validates metrics schema conformance.
  - `flowscribe verify-costs` reconciles with OpenRouter usage data.

## Roadmap

### Phase 1 (Completed âœ…)
- Canonical metrics schema (v1.0)
- Usage-first cost tracking
- Violations table (Level 2)
- Dynamic LLM-based architecture review
- Mermaid rich layered visualization

### Phase 2 (In Progress ğŸš§)
- Full provenance and validation chain
- Cost reconciliation from OpenRouter dashboard
- Metrics aggregator (flowscribe-analyze)
- Multi-repo and plugin support
- Rule-weighted dependency visualization

### Phase 3 (Planned ğŸ§©)
- Multi-threaded generation
- Interactive dashboards (metrics + visualization)
- Integration with CI/CD pipelines
- Enhanced audit trail and anomaly detection

## License
Â© 2025 Flowscribe Project. MIT License.
